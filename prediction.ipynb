{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from os import walk\n",
    "from sklearn.feature_selection import mutual_info_regression, f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/Volumes/KM/Archive/KaggleStuff/2017SBER/transformed_data/new/train_v4.csv')\n",
    "df_test = pd.read_csv('/Volumes/KM/Archive/KaggleStuff/2017SBER/transformed_data/new/test_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'full_sq', 'sport_count_5000', 'sport_count_3000',\n",
       "       'trc_count_5000', 'zd_vokzaly_avto_km', 'sadovoe_km',\n",
       "       'sport_count_2000', 'bulvar_ring_km', 'kremlin_km', 'ttk_km',\n",
       "       'trc_sqm_5000', 'nuclear_reactor_km', 'sport_count_1500',\n",
       "       'office_sqm_5000', 'sport_objects_raion', 'trc_count_3000',\n",
       "       'stadium_km', 'cafe_count_5000_price_1000', 'detention_facility_km',\n",
       "       'basketball_km', 'cafe_count_5000_price_1500', 'office_km',\n",
       "       'cafe_count_5000', 'cafe_count_5000_na_price', 'university_km',\n",
       "       'trc_sqm_3000', 'cafe_count_5000_price_500', 'workplaces_km',\n",
       "       'cafe_count_5000_price_2500', 'office_sqm_3000', 'swim_pool_km',\n",
       "       'thermal_power_plant_km', 'office_count_5000', 'catering_km',\n",
       "       'exhibition_km', 'church_count_5000', 'office_sqm_2000',\n",
       "       'cafe_count_5000_price_high', 'cafe_count_5000_price_4000',\n",
       "       'big_church_km', 'school_education_centers_raion', 'sport_count_1000',\n",
       "       'fitness_km', 'metro_min_avto', 'market_count_5000', 'park_km',\n",
       "       'big_church_count_5000', 'leisure_count_5000', 'office_sqm_1500',\n",
       "       'ekder_male', 'metro_km_avto', 'trc_count_2000', 'shopping_centers_km',\n",
       "       'public_healthcare_km', 'ekder_all', 'ekder_female',\n",
       "       'cafe_count_3000_price_1000', 'office_count_1500', 'raion_popul',\n",
       "       'usdrub', 'eurrub', 'cafe_count_2000', 'theater_km', 'office_raion',\n",
       "       'indust_part', 'sale_year', 'sale_month', 'life_sq', 'life_sq_lg1',\n",
       "       'floor', 'max_floor', 'num_room', 'kitch_sq', 'max_floor_lg1',\n",
       "       'kitch_sq_lg1', 'state', 'material', 'build_year', 'unbuilt',\n",
       "       'state_xg1', 'state_0', 'state_1', 'state_2', 'state_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nans(field, dff):\n",
    "    return (pd.isnull(dff[field]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_nans('price', df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgeoblapenko/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/georgeoblapenko/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df_train['full_sq'][df_train['full_sq'] == 0] = df_train['life_sq'][df_train['full_sq'] == 0]\n",
    "df_test['full_sq'][df_test['full_sq'] == 0] = df_test['life_sq'][df_test['full_sq'] == 0]\n",
    "\n",
    "df_train['full_sq'][df_train['full_sq'] == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr = 'usd'\n",
    "curr = 'eur'\n",
    "# curr = 'rub'\n",
    "\n",
    "log_scale = True\n",
    "\n",
    "if curr == 'rub':\n",
    "    target = 'price'\n",
    "else:\n",
    "    target = 'price_' + curr\n",
    "\n",
    "features_001 = ['id', 'life_sq', 'max_floor', 'num_room', 'kitch_sq', 'build_year', 'state', 'state_xg1', 'material']\n",
    "    \n",
    "features = [c for c in df_test.columns if c not in features_001]\n",
    "# df_train = df_train[df_train['material_flag'] == False]\n",
    "features.append('lsq_fsq')\n",
    "\n",
    "df_train = df_train[~pd.isnull(df_train['floor'])]\n",
    "\n",
    "df_train['lsq_fsq'] = df_train['life_sq_lg1'] / df_train['full_sq']\n",
    "df_test['lsq_fsq'] = df_test['life_sq_lg1'] / df_test['full_sq']\n",
    "df_train['ksq_fsq'] = df_train['kitch_sq_lg1'] / df_train['full_sq']\n",
    "df_test['ksq_fsq'] = df_test['kitch_sq_lg1'] / df_test['full_sq']\n",
    "\n",
    "\n",
    "\n",
    "target_scaler = StandardScaler()\n",
    "\n",
    "if log_scale:\n",
    "    target_vals = np.log(df_train[target].values + 1)\n",
    "else:\n",
    "    target_scaler.fit(df_train[target].values.reshape(-1, 1))\n",
    "    target_vals = target_scaler.transform(df_train[target].values.reshape(-1, 1))\n",
    "# target_vals = target_vals.ravel()\n",
    "\n",
    "train_features = df_train[features].values\n",
    "\n",
    "# f_k = SelectKBest(f_regression, 50)\n",
    "# train_features = f_k.fit_transform(df_train[features].values, target_vals)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_features)\n",
    "\n",
    "train_features = scaler.transform(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full_sq', 'sport_count_5000', 'sport_count_3000', 'trc_count_5000', 'zd_vokzaly_avto_km', 'sadovoe_km', 'sport_count_2000', 'bulvar_ring_km', 'kremlin_km', 'ttk_km', 'trc_sqm_5000', 'nuclear_reactor_km', 'sport_count_1500', 'office_sqm_5000', 'sport_objects_raion', 'trc_count_3000', 'stadium_km', 'cafe_count_5000_price_1000', 'detention_facility_km', 'basketball_km', 'cafe_count_5000_price_1500', 'office_km', 'cafe_count_5000', 'cafe_count_5000_na_price', 'university_km', 'trc_sqm_3000', 'cafe_count_5000_price_500', 'workplaces_km', 'cafe_count_5000_price_2500', 'office_sqm_3000', 'swim_pool_km', 'thermal_power_plant_km', 'office_count_5000', 'catering_km', 'exhibition_km', 'church_count_5000', 'office_sqm_2000', 'cafe_count_5000_price_high', 'cafe_count_5000_price_4000', 'big_church_km', 'school_education_centers_raion', 'sport_count_1000', 'fitness_km', 'metro_min_avto', 'market_count_5000', 'park_km', 'big_church_count_5000', 'leisure_count_5000', 'office_sqm_1500', 'ekder_male', 'metro_km_avto', 'trc_count_2000', 'shopping_centers_km', 'public_healthcare_km', 'ekder_all', 'ekder_female', 'cafe_count_3000_price_1000', 'office_count_1500', 'raion_popul', 'usdrub', 'eurrub', 'cafe_count_2000', 'theater_km', 'office_raion', 'indust_part', 'sale_year', 'sale_month', 'life_sq_lg1', 'floor', 'max_floor_lg1', 'kitch_sq_lg1', 'unbuilt', 'state_0', 'state_1', 'state_2', 'state_3', 'lsq_fsq']\n"
     ]
    }
   ],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regressor1 = XGBRegressor(max_depth=2, learning_rate=0.014, n_estimators=2500, subsample=0.78, gamma=0.0) \n",
    "regressor2 = GradientBoostingRegressor(max_depth=4, learning_rate=0.012, n_estimators=2000, subsample=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50096265057830425, 0.47550892149506013] 0.488235786037\n"
     ]
    }
   ],
   "source": [
    "n_splits = 2\n",
    "def validate():\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    res = []\n",
    "    for train_index, test_index in kf.split(train_features):\n",
    "        regressor2.fit(train_features[train_index], target_vals[train_index])\n",
    "        pred = regressor2.predict(train_features[test_index])\n",
    "        \n",
    "        if log_scale:\n",
    "            truth = target_vals[test_index]\n",
    "            res.append(np.sqrt(np.mean(np.square(pred - truth))))\n",
    "        else:\n",
    "            pred = target_scaler.inverse_transform(pred)\n",
    "            truth = target_scaler.inverse_transform(target_vals[test_index])\n",
    "            res.append(np.sqrt(np.mean(np.square(np.log(pred + 1) - np.log(truth + 1)))))\n",
    "    return res\n",
    "r = validate()\n",
    "print(r, sum(r) / n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0.0, learning_rate=0.014, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=2200, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.75)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor3 = XGBRegressor(max_depth=3, learning_rate=0.014, n_estimators=2200, subsample=0.75, gamma=0.0) \n",
    "regressor3.fit(train_features, target_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.012, loss='ls', max_depth=4,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=2000, presort='auto', random_state=None,\n",
       "             subsample=0.75, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor1.fit(train_features, target_vals)\n",
    "regressor2.fit(train_features, target_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = df_test[features].values\n",
    "# test_features = f_k.transform(df_test[features].values)\n",
    "test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out1 = regressor1.predict(test_features)\n",
    "out2 = regressor2.predict(test_features)\n",
    "out3 = regressor3.predict(test_features)\n",
    "if log_scale:\n",
    "    out_scaled1= np.exp(out1) - 1\n",
    "    out_scaled2= np.exp(out2) - 1\n",
    "    out_scaled3= np.exp(out3) - 1\n",
    "else:\n",
    "    out_scaled1 = target_scaler.inverse_transform(out1)\n",
    "    out_scaled2 = target_scaler.inverse_transform(out2)\n",
    "    out_scaled3 = target_scaler.inverse_transform(out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(out_scaled1.shape) > 1:\n",
    "    out_scaled1 = out_scaled1[:, 0]\n",
    "    out_scaled2 = out_scaled2[:, 0]\n",
    "    out_scaled3 = out_scaled3[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w1 = 0.6\n",
    "w2 = 0.2\n",
    "w3 = 0.2\n",
    "\n",
    "dfn_test = pd.DataFrame()\n",
    "\n",
    "if curr == 'rub':\n",
    "    dfn_test['price_doc'] = (w1 * out_scaled1 + w2 * out_scaled2 + w3 * out_scaled3)\n",
    "elif curr == 'usd':\n",
    "    dfn_test['price_doc'] = df_test['usdrub'] * (w1 * out_scaled1 + w2 * out_scaled2 + w3 * out_scaled3)\n",
    "else:\n",
    "    dfn_test['price_doc'] = df_test['eurrub'] * (w1 * out_scaled1 + w2 * out_scaled2 + w3 * out_scaled3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfn_test['id'] = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "cutoff = 300000\n",
    "nonpos = (dfn_test['price_doc'] < cutoff).sum()\n",
    "print(nonpos)\n",
    "if nonpos > 0:\n",
    "    avg_pos = np.average(dfn_test['price_doc'][dfn_test['price_doc'] > cutoff].values)\n",
    "    dfn_test.loc[dfn_test['price_doc'] < 0, 'price_doc'] = avg_pos\n",
    "nonpos = (dfn_test['price_doc'] < cutoff).sum()\n",
    "print(nonpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff = 50000000\n",
    "(dfn_test['price_doc'] > cutoff).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n",
      "14 14\n",
      "15 15\n",
      "16 16\n",
      "17 17\n",
      "18 18\n",
      "19 19\n",
      "2 2\n",
      "20 20\n",
      "21 21\n",
      "22 22\n",
      "23 23\n",
      "24 24\n",
      "25 25\n",
      "26 26\n",
      "27 27\n",
      "28 28\n",
      "29 29\n",
      "3 3\n",
      "30 30\n",
      "31 31\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "maxname = 0\n",
    "for root, dirs, files in walk('/Volumes/KM/Archive/KaggleStuff/2017SBER/submissions/new'):\n",
    "    for name in files:\n",
    "        if name.endswith('.csv'):\n",
    "            print(name[:-4], int(name[:-4]))\n",
    "            maxname += 1\n",
    "print(maxname)\n",
    "dfn_test.to_csv('/Volumes/KM/Archive/KaggleStuff/2017SBER/submissions/new/' + str(maxname)+ '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
